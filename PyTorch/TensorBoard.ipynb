{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb0b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop (batch training)\n",
    "# Model evaluation\n",
    "# GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b978d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028b552",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f8a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with command \"tensorboard --logdir=runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8482ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d4263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 #28x28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564983fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d692e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3f207f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "#plt.show()\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12c0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # don't want Softmax here\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6ea717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x100)\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:841\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    837\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[1;32m--> 841\u001b[0m         graph(model, input_to_model, verbose, use_strict_trace)\n\u001b[0;32m    842\u001b[0m     )\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:343\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurs, No graph saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:337\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m         trace \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mtrace(model, args, strict\u001b[38;5;241m=\u001b[39muse_strict_trace)\n\u001b[0;32m    338\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[0;32m    339\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\jit\\_trace.py:794\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    795\u001b[0m         func,\n\u001b[0;32m    796\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    798\u001b[0m         check_trace,\n\u001b[0;32m    799\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[0;32m    800\u001b[0m         check_tolerance,\n\u001b[0;32m    801\u001b[0m         strict,\n\u001b[0;32m    802\u001b[0m         _force_outplace,\n\u001b[0;32m    803\u001b[0m         _module_class,\n\u001b[0;32m    804\u001b[0m         example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(example_kwarg_inputs, \u001b[38;5;28mdict\u001b[39m),\n\u001b[0;32m    805\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs\n\u001b[0;32m    806\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m ):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\jit\\_trace.py:1056\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m-> 1056\u001b[0m     module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_create_method_from_trace(\n\u001b[0;32m   1057\u001b[0m         method_name,\n\u001b[0;32m   1058\u001b[0m         func,\n\u001b[0;32m   1059\u001b[0m         example_inputs,\n\u001b[0;32m   1060\u001b[0m         var_lookup_fn,\n\u001b[0;32m   1061\u001b[0m         strict,\n\u001b[0;32m   1062\u001b[0m         _force_outplace,\n\u001b[0;32m   1063\u001b[0m         argument_names,\n\u001b[0;32m   1064\u001b[0m         _store_inputs\n\u001b[0;32m   1065\u001b[0m     )\n\u001b[0;32m   1067\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1(x)\n\u001b[0;32m     11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2(out)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x100)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer.add_graph(model, samples)\n",
    "writer.close()\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #backwards\n",
    "        optimizer.zero_grad() # empty the values in the gradient attribute\n",
    "        loss.backward()\n",
    "        optimizer.step()      # updates the parameters \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 ==0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095f9ea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     class_predictions \u001b[38;5;241m=\u001b[39m [F\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n\u001b[0;32m     21\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(class_predictions)\n\u001b[1;32m---> 22\u001b[0m     labels1\u001b[38;5;241m.\u001b[39mappend(predicted)\n\u001b[0;32m     24\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mstack(batch) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m preds])\n\u001b[0;32m     25\u001b[0m labels1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(labels1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# In test phase, we don't need to compute graidents (for memory efficiency)\n",
    "\n",
    "labels1 = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels2 in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels2 = labels2.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels2.shape[0]\n",
    "        n_correct += (predictions == labels2).sum().item()\n",
    "        \n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        \n",
    "        pred.append(class_predictions)\n",
    "        labels1.append(predicted)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels1 = torch.cat(labels1)\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels ==i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
